\section{Introduction}\label{sec:intro}

Supervised recursive neural network models (RNNs) for sentence meaning
have been successful in an array of sophisticated language tasks,
including sentiment analysis \cite{socher2011semi,socher2013acl1},
image description \cite{sochergrounded}, and paraphrase detection
\cite{Socher-etal:2011:Paraphrase}. These results are encouraging for
the ability of these models to learn compositional semantic grammars.
However, it remains an open question whether they can achieve the
high-fidelity distributed representations of recent algebraic
approaches \cite{ClarkCoeckeSadrzadeh2011,grefenstette2013towards,rocktaschellow},
and whether they can match the performance of grammars based in logical forms
\cite{Warren:Pereira:1982,Zelle:Mooney:1996,ZetCol:2005,LiangJordan:2013}
when it comes to the core semantic concepts of quantification,
entailment, and contradiction needed to identify the relationships
between sentences like \ii{every animal walks}, \ii{every turtle
 moves}, and \ii{most reptiles don't move}.

To date, experimental investigations of these concepts using
distributed representations have been largely confined to short
phrases \cite{Mitchell:Lapata:2010,Grefenstette-etal:2011,baroni2012entailment}.
However, for robust natural language understanding, it is essential to
model these phenomena in their full generality on complex linguistic
structures. Recent work on the algebraic approach of
\newcite{ClarkCoeckeSadrzadeh2011} has yielded rich frameworks 
for computing the meanings of complex fragments of natural
language compositionally from vector or tensor representations, but 
has not yet yielded effective methods for learning these representations
entirely from data in a typical machine learning setting.

Our research uses the task of \ii{natural language inference} 
(also known as \ii{recognizing textual entailment};
\citealt{dagan2006pascal}), in which the goal is to determine the core
inferential relationship between two sentences. Much of the
theoretical work on this task (and some successful implemented models;
\citealt{maccartney2009extended,watanabe2012latent}) involves \ii{natural
  logics}, which are formal systems that define rules of inference
between natural language words, phrases, and sentences without the
need of intermediate representations in an artificial logical
language. We use the natural logic developed by
\newcite{maccartney2009extended} as our formal model. This logic
defines seven core relations of synonymy, entailment, contradiction,
and mutual consistency, as summarized in Table~\ref{b-table}, and it
provides rules of semantic combination for projecting these relations
from the lexicon up to complex phrases. The formal properties and
inferential strength of this system are now well-understood
\cite{Icard:Moss:2013,Icard:Moss:2013:LILT}.

In our first set of experiments, we use this pre-specified logical
grammar to generate controlled data sets encoding the semantic
relationships between pairs of expressions and evaluate whether each
of two classes of neural model---plain recursive NNs and recursive neural
tensor networks (RNTNs; \citealt{socher2013acl1})---can learn those
relationships correctly. In our first experiment
(Section~\ref{sec:join}), we evaluate the ability of these models to
learn the core relational algebra of natural logic from data. Our
second experiment (Section~\ref{sec:recursion}) extends this
evaluation to relations between complex recursive structures like
$(a \plor b)$ and $\plneg (\plneg a \pland \plneg b)$, and our third
experiment (Section~\ref{sec:quantifiers}) involves relations between
quantified statements like \ii{every reptile walks} and \ii{no turtle
  moves}. \mynote{Though the performance of the plain RNN model 
 is somewhat poor in one experiment, we find that the stronger RNTN
  model generalizes well in every case, suggesting that it has in fact
  learned, or at least learned to simulate, our target logical
  concepts.}

The experiments with simulated data provide a convincing demonstration
of the ability of neural networks to learn to encode semantic
inferences in complex natural language sentences from reasonably-sized
training sets. However, we are also interested in the more practical
question of whether they can learn these representations from more
naturalistic text. To address this question, we apply our models to
the SICK entailment challenge data. The small size of this corpus puts
data-intensive neural models like ours at a disadvantage, but we are
nonetheless able to achieve competitive performance on it,
\mynote{surpassing several models with significant hand engineered task specific features.}
This suggests that the representational abilities that we observe in the previous sections
are not limited to carefully circumscribed tasks. We conclude that RNTN models
are adequate for typical cases of natural logic inference, and that there is not yet
any clear level of inferential complexity for which other approaches work and NN models fail.


\begin{table*}[tp]
  \centering\small
  \setlength{\tabcolsep}{15pt}
  \renewcommand{\arraystretch}{1}
  \begin{tabular}{l c l l} 
    \toprule
    Name & Symbol & Set-theoretic definition & Example \\ 
    \midrule
    entailment         & $x \natfor y$   & $x \subset y$ & \ii{turtle, reptile}  \\ 
    reverse entailment & $x \natrev y$   & $x \supset y$ & \ii{reptile, turtle}  \\ 
    equivalence        & $x \nateq y$    & $x = y$       & \ii{couch, sofa} \\ 
    alternation        & $x \natalt y$   & $x \cap y = \emptyset \wedge x \cup y \neq \mathcal{D}$ & \ii{turtle, warthog} \\ 
    negation           & $x \natneg y$   & $x \cap y = \emptyset \wedge x \cup y = \mathcal{D}$    & \ii{able, unable} \\
    cover              & $x \natcov y$   & $x \cap y \neq \emptyset \wedge x \cup y = \mathcal{D}$ & \ii{animal, non-turtle} \\ 
    independence       & $x \natind y$   & (else) & \ii{turtle, pet}\\
    \bottomrule
  \end{tabular}
  \caption{\label{b-table}The seven natural logic relations of MacCartney and Manning \protect\shortcite{maccartney2009extended}. 
    $\mathcal{D}$ is the universe of possible objects of the same type as those being compared, 
    and the relation $\natind$ applies where none of the other six do.} %, including when there 
    %is insufficient knowledge to choose a label.}
 
\end{table*}


% Citations to additional past work to be added.\\...\\...\\...\\...\\...


% Deep learning methods in NLP which learn vector representations for words have seen successful uses in recent years on increasingly sophisticated tasks \cite{collobert2011natural, socher2011semi, socher2013acl1, chen2013learning}. Given the still modest performance of semantically rich NLP systems in many domains---question answering and machine translation, for instance---it is worth exploring the degree to which learned vectors can serve as general purpose semantic representations. Much of the work to date analyzing vector representations for words (see \cite{baroni2013frege}) has focused on lexical semantic behaviors---like the similarity between words like \ii{Paris} and \ii{France}. Good similarity functions are valuable for many NLP tasks, but there are real use cases for which it is necessary to know how words relate to one another or to some extrinsic representation, and to model the ways in which word meanings combine to form phrase, sentence, or document meanings. This paper explores the ability of linguistic representations developed using supervised deep learning techniques to support interpretation and reasoning. 

% There are two broad family of tasks that could be used to test the ability of a model to develop general purpose meaning representations. In an interpretation task, sentences are mapped onto some denotation, such as  \ii{true} or \ii{false} for statements, or a factual answer for questions. There has been preliminary work in developing distributed models for interpretation \cite{grefenstette2013towards, rocktaschellow}, but developing a representation of world knowledge that corresponds accurately to the content expressed in language introduces considerable design challenges. I approach the problem by way of an inference task instead. Inferring the truth of one sentence from another does not require any preexisting knowledge representations, but nonetheless requires a precise representation of sentence meaning. I borrow the structure of the task from MacCartney and Manning  \cite{maccartney2009extended}. In it, the model is presented with a pair of sentences, and made to label the logical relation between the sentences as equivalence, entailment, or any of five other classes, as here:

%\begin{quote}
%\begin{enumerate}\small
%\item Many smartphone users avoid high bills overseas by disabling data service.
%\item Not everyone uses their smartphones for email when traveling abroad.
%\end{enumerate} 
%$\Rightarrow$ Entailment
%\end{quote}

%In this paper, we test the ability of recursive models to on three simple tasks, each of which is meant to capture a property that is necessary in representing natural language meaning in the setting of inference. I begin with an overview of MacCartney and Manning's \cite{maccartney2009extended} framework for inference, and of the recursive neural networks that I study. by showing that these models can learn to correctly represent entailment representations between sentences. I then show that these models can capture the meanings of recursive structures accurately up to a sufficient depth. I finally close with a brief demonstration of the ability of these models to reason over short natural language sentences involving quantifiers. 

% \subsection{Natural language inference and natural logic}

% In its simplest form, \ii{natural language inference} (also known as \ii{recognizing textual entailment}, as in \cite{dagan2006pascal}) is the task of determine whether one sentence entails another. Much of the theoretical work on this task (and some successful implemented models \cite{maccartney2009natural, watanabe2012latent}) involve \ii{natural logic}, formal systems that define sound rules of inference from one sentence of natural language to another without the need for intermediate representations in some other logic. The most powerful model that we are aware of for natural logic is due to MacCartney and Manning \cite{maccartney2009extended} and Icard \cite{icard2012inclusion}, and is centered around the definition of a set of seven logical relations which can hold between sentences, shown in Table \ref{b-table}.

% This approach to natural logic can capture much of the complexity of natural language meaning within a well understood framework, and is also fairly straightforward to implement in a machine learning setting since it can be reduced to a seven-way classification problem on sentence pairs. Our goal in this paper is to learn recursive neural network models which are able to mimic key behaviors of this system.

% \begin{table}
% \begin{center}
% \begin{tabular}{|c|c|c|c|} \hline
% name & symbol & set-theoretic definition & example \\ \hline \hline
% entailment & $x \sqsubset y$ & $x \subset y$ & \ii{crow, bird}  \\ \hline
% reverse entailment & $x \sqsupset y$ & $x \supset y$ & \ii{Asian, Thai}  \\ \hline
% equivalence & $x \equiv y$ & $x = y$ & \ii{couch, sofa} \\ \hline
% alteration & $x$ $|$ $y$ & $x \cap y = \emptyset \wedge x \cup y \neq \mathcal{D}$ & \ii{cat, dog} \\ \hline
% negation & $x \natneg y$ & $x \cap y = \emptyset \wedge x \cup y = \mathcal{D}$ & \ii{able, unable} \\ \hline
% cover & $x \smallsmile y$ & $x \cap y \neq \emptyset \wedge x \cup y = \mathcal{D}$ & \ii{animal, non-ape} \\ \hline
% independence & $x$ \# $y$ & (else) & \ii{hungry, hippo}\\ \hline
% \end{tabular}
% \caption{The entailment relations in  $\mathfrak{B}$. $\mathcal{D}$ is the universe of possible objects of the same type as those being compared, and the relation \# applies whenever none of the other six do, including when there is insufficient knowledge to choose a label.}
% \label{b-table}
% \end{center}
% \end{table}

% The goal of each of the three experiments that we propose is to learn classifiers that are able to classify pairs of statements from some highly constrained language into these seven classes. It should be noted that this is not a balanced classification problem. If arbitrary pairs of statements are chosen for comparison in almost any domain of natural language, the minimally informative \# relation will apply between them. %  How much should we say about this?


% The natural logic engine at the core of MacCartney and Manning's system requires a complex set of linguistic knowledge, much of which takes the form of what he calls projectivity signatures. These signatures are tables showing the entailment relation that must hold between two strings that differ in a given way (such as the substitution of the argument of some quantifier), and are explicitly provided to the model
%for dozens of different cases of insertion, deletion and substitution of different types of lexical item. For example in judging the inference \ii{no animals bark $|$ some dogs bark} it would first used stored knowledge to compute the relations introduced by each of the two differences between the sentences. Here, the substitution of \ii{no} for \ii{some}  yields $\natneg$ and the substitution of \ii{dogs} for \ii{animals} yields $\sqsupset$. It would then use an additional store of knowledge about relations to resolve the resulting series of relations into one ($|$) that expresses the relation between the two sentences being compared:
%\begin{quote}

%1. \ii{no animals bark $\natneg$ \textbf{some} animals bark}\\
%2. \ii{some animals bark $\sqsupset$ some \textbf{dogs} bark}\\
%3. \ii{no animals bark $[\natneg\bowtie\thinspace\sqsupset\thinspace = |]$ some dogs bark}

%\end{quote}

% Work to date on inference in neural network models is quite limited.
% \citet{baroni2012entailment} have achieved limited success in building a classifier to judge entailments between one- and two-word phrases (including some with quantifiers), though their vector representations were crucially based on distributional statistics and were not  learned for the task.
% In another line of research, \citet{garrette2013formal} propose a way to improve standard discrete NLI with vector representations. They propose a deterministic inference engine (similar to MacCartney's) which is augmented by a probabilistic component that evaluates individual lexical substitution steps in the derivation using vector representations, though again these representations are not learned, and no evaluations of this system have been published to date.
% \label{sec2}
