\begin{abstract} 
  Tree-structured recursive neural networks (TreeRNNs) for sentence meaning have been
  successful for many applications, but it remains an open question whether
  the fixed-length representations that they learn can support tasks as demanding as logical deduction.
  We pursue this question by evaluating whether two such models---plain TreeRNNs and tree-structured neural
  tensor networks (TreeRNTNs)---can correctly learn to identify logical
  labelships such as entailment and contradiction using these representations. 
  In our first set of experiments, we generate artificial data from a
  logical grammar and use it to evaluate the models' ability to learn
  to handle basic labelal reasoning, recursive structures, and
  quantification. We then evaluate the models on the more natural
  SICK challenge data. Both models perform competitively on the SICK
  data and generalize well in all three experiments on simulated data,
  suggesting that they can learn suitable representations for logical
  inference in natural language. 
\end{abstract}
