\section{Reasoning about semantic relations}\label{sec:join}

In this experiment, we test our model's ability to learn and use
the natural logic inference rules schematized in 
Figure~\ref{tab:jointable}. For instance, given that $a \natrev b$ and $b
\natrev c$, one can conclude that $a \natrev c$, by basic
set-theoretic reasoning (transitivity of $\natrev$). Similarly, from
$a \natfor b$ and $b \natneg c$, it follows that $a \natalt c$. Cells in the
table containing a dot correspond to pairs of relations for which no valid 
inference can be drawn in our logic.

% about the relations themselves that do not depend on the
% internal structure of the things being compared. For example, given
% that $a\sqsupset b$ and $b\sqsupset c$ one can conclude that
% $a\sqsupset c$ by the transitivity of $\sqsupset$, even without
% understanding $a$, $b$, or $c$. These seven relations support more
% than just transitivity: MacCartney and Manning's
% \cite{maccartney2009extended} join table defines 32 valid inferences
% that can be made on the basis of pairs of relations of the form $a R
% b$ and $b R' c$, including several less intuitive ones such as that if
% $a \natneg b$ and $b~|~c$ then $a \sqsupset c$.

\paragraph{Experiments}
To test our models' ability to learn these inferential patterns, we
create artificial boolean structures in which terms denote sets of entities from
a small domain (e.g., Figure~\ref{lattice-figure}), employ logical
deduction to identify the valid statements, divide those into train
and test sets, and remove from the test set those statements which
cannot be proven from the training statements
(Figure~\ref{unprovable}).
% using the logic depicted in Figure~\ref{lattice-figure}.
%
%
% We test the model's ability to learn this behavior by creating
% artificial data sets of terms which represent sets of numbers. Since
% MacCartney and Manning's set of relations hold between sets as well as
% between sentences, we can use the underlying set structure to generate
% the all of the relations that hold between any pair of these terms, as
% in Figure \ref{lattice-figure}. We train the model defined above on a
% subset of these relations, but rather then presenting the model with a
% pair of tree-structured sentences as inputs, simply present it with
% two single terms, each of which corresponds to a single vector in the
% (randomly initialized) vocabulary matrix $V$, ensuring that the model
% has no information about the terms being compared except the relations
% between them.
%
In our experiments, we create 80 randomly generated sets drawn from a
domain of seven elements. This yields 6400 statements about pairs of
formulae, of which 3200 are chosen as a test set, and that test set is
further reduced to the 2960 examples that can be provably derived from
the training data. We trained both the NN model and the NTN model on
these data
sets.% . In both cases, the models were implemented exactly as
% described in Section~\ref{methods}, but since the items being compared
% are single terms rather than full tree structures, the composition
% layer was not involved, and the two models differed only in which
% layer function was used for the comparison layer. We simply present
% the models with two single terms, each of which corresponds to a
% single vector in the (randomly initialized) vocabulary matrix $V$,
% thereby ensuring that the model has no information about the terms
% being compared except the relations between them.

\paragraph{Results} 
We found that the NTN model worked best with 11-dimensional vector
representations for the 80 sets and a 90-dimensional feature vector
for the classifier, though the performance of the model was not highly
dependant on either dimensionality setting. 
Averaging over five randomly generated data sets, the model was able to correctly label 98.1\% (standard error $0.67\%$) of the provably derivable test examples, and 87.7\%
($SE = 3.59\%$) of the remaining test examples. The simpler NN worked
best with 11 and 75 dimensions, respectively, but was able to achieve
accuracies of only 84.8\% ($SE = 0.84\%$) and 68.7\% ($SE = 1.58\%$),
respectively. Training accuracy was 99.8\% ($SE = 0.04\%$) for the NTN and 94.7\% ($SE= 0.89\%$) for
the NN.

\begin{figure}[tp]
  \centering
  \begin{subfigure}[b]{0.42\textwidth}
    \centering  
    \setlength{\arraycolsep}{8pt}
    \renewcommand{\arraystretch}{1.1}
    \newcommand{\UNK}{\cdot}  
    \resizebox{2.2in}{!}{$\begin{array}[c]{c@{ \ }|*{7}{c}|}
        % \hline
        \multicolumn{1}{c}{}
        & \nateq     & \natfor     & \natrev     & \natneg    & \natalt     & \natcov     & \multicolumn{1}{c}{\natind} \\
        \cline{2-8}
        \nateq  & \nateq &   \natfor &  \natrev &  \natneg &   \natalt &  \natcov &  \natind \\
        \natfor & \natfor &  \natfor &  \UNK &  \natalt &   \natalt &  \UNK &  \UNK \\
        \natrev & \natrev &  \UNK &  \natrev &  \natcov &   \UNK &  \natcov &  \UNK \\
        \natneg & \natneg &  \natcov &  \natalt &  \nateq &    \natrev &  \natfor &  \natind \\
        \natalt & \natalt &  \UNK &  \natalt &  \natfor &   \UNK &  \natfor &  \UNK \\
        \natcov & \natcov &  \natcov &  \UNK &  \natrev &   \natrev &  \UNK &  \UNK \\
        \natind & \natind & \UNK &  \UNK &  \natind &  \UNK &  \UNK &  \UNK \\
        \cline{2-8}
      \end{array}$}
    \caption{Inference path from premises $a\,R\,b$ (row) and $b\,S\,c$ (column) to the relation that holds between $a$ and $c$, if any.  These inferences are based on basic set-theoretic truths about the meanings of the underlying relations as described in Table~\ref{b-table}. We assess our models' ability to reproduce such inferential paths.}
    \label{tab:jointable}
  \end{subfigure}
  \hfill
  \begin{subfigure}[b]{0.3\textwidth}
    \centering
    \newcommand{\labelednode}[4]{\put(#1,#2){\oval(1.5,1)}\put(#1,#2){\makebox(0,0){$\begin{array}{c}#3\\\{#4\}\end{array}$}}}
    \setlength{\unitlength}{1cm}
    \resizebox{1.5in}{!}{\begin{picture}(5,5.5)
      \labelednode{2.50}{5}{}{1,2,3}
      
      \put(0.75,4){\line(3,1){1.5}}
      \put(2.5,4){\line(0,1){0.5}}
      \put(4.25,4){\line(-3,1){1.5}}
      
      \labelednode{0.75}{3.5}{a,b}{1,2}
      \labelednode{2.50}{3.5}{c}{1,3}
      \labelednode{4.25}{3.5}{d}{2,3}
      
      \put(0.75,2.5){\line(0,1){0.5}}
      \put(0.75,2.5){\line(3,1){1.5}}
      
      \put(2.5,2.5){\line(-3,1){1.5}}
      \put(2.5,2.5){\line(3,1){1.5}}
      
      \put(4.25,2.5){\line(0,1){0.5}}
      \put(4.25,2.5){\line(-3,1){1.5}}
      

      \labelednode{0.75}{2}{e,f}{1}
      \labelednode{2.50}{2}{}{2}
      \labelednode{4.25}{2}{g,h}{3}
      
      \put(2.5,1){\line(-3,1){1.5}}
      \put(2.5,1){\line(0,1){0.5}}
      \put(2.5,1){\line(3,1){1.5}}
      
      \labelednode{2.5}{0.5}{}{}
    \end{picture}}
    \caption{Simple boolean structure. The letters name the sets. Not all sets have names, and
    some sets have multiple names, so that learning $\nateq$ is non-trivial.}\label{lattice-figure}
  \end{subfigure}
  \hfill
  \begin{subfigure}[b]{0.2\textwidth}
    \centering
    \setlength{\tabcolsep}{12pt}
    \resizebox{1.05in}{!}{\begin{tabular}[c]{c  c}
      \toprule
      Train & Test \\
      \midrule
                    & $b \nateq b$ \\
      $b \natcov c$ &               \\
                    & $b \natcov d$ \\
                    & \strikeout{$b \natrev e$} \\
      $c \natcov d$ &               \\
      $c \natrev e$ &               \\
                    & \strikeout{$c \nateq f$} \\
      $c \natrev g$ &               \\ 
                    & $e \natfor b$ \\
      $e \natfor c$ &               \\[-1ex]
      $\vdots$      & $\vdots$ \\
      \bottomrule
    \end{tabular}}

    \caption{A train/test split of the atomic statements about the
      model.  Test statements not provable from the training data are
      crossed out.}\label{unprovable}
  \end{subfigure}  
  \caption{Experimental goal and set-up for reasoning about semantic relations.}
  \label{exp1}
\end{figure} 
% Note: None of these test examples is derivable from the shown training data, 
% but we suggest that there is additional training data, so we can cross lines
% out willy-nilly without fear.

% RNTN log: tue-j-11-6x80-hip.txt
% Train PER: 0.0021875

% RNN log: tue-j-11-6x80-r-75.txt
% Train PER: 0.047188

% and create a dataset consisting of the relations between every pair of
% sets, yielding 6400 pairs. 3200 of these pairs are then chosen as a
% test dataset, and that test dataset was further split into the 2960
% examples that can be provably derived from the test data using
% MacCartney and Manning's join table (or by the symmetry of the
% relations in about half of the cases) and the 240 that
% cannot. 

% We tested a version of both the RNN model and the RNTN model on these
% data. In both cases, the models were implemented exactly as described
% in Section~\ref{methods}, but since the items being compared are
% single terms rather than full tree structures, the composition layer
% was not used, and the two models differed only in which layer function
% was used for the comparison layer. We found that the RNTN model worked
% best with 11 dimensional vector representations for the 80 sets and a
% 90 dimensional feature vector for the classifier. This model was able
% to correctly label 99.3\% of the derivable test examples, and 99.1\%
% of the remaining examples. The simpler RNN model worked best with 11
% and 75 dimensions, respectively, but was able to achieve accuracies of
% only 90.0\% and 87.\%, respectively.

These results are fairly straightforward to interpret. The NTN model
was able to accurately encode the relations between the terms in the
geometric relations between their vectors, and was able to then use
that information to recover relations that were not overtly included
in the training data. In contrast, the NN was able to achieve this
behavior only incompletely. It is possible but not likely that it
could be made to find a good solution with further optimization on
different learning algorithms, or that it would do better on a larger
universe of sets, for which there would be a larger set of training
data to learn from, but the NTN is readily able to achieve these
effects in the setting discussed here.

