\section{General discussion}\label{sec:discussion}

This paper evaluated two RNNs in a series of three increasingly
challenging interpretive tasks involving natural language inference:
the core relational algebra of natural logic with entailment and
exclusion; recursive propositional logic structures; and statements
involving quantification and negation. The results suggest that RNTNs,
but not plain RNNs, have the capacity to meet the challenges of these
tasks with reasonably-sized training sets. These positive results are
promising for the future of learned representation models in the
applied modeling of compositional semantics.

Of course, challenges remain. In terms of our experimental data, even
the RNTN falls short of perfection in our more complex tasks, with
performance falling off steadily as the depth of recursion grows. It
remains to be seen whether these deficiencies can be overcome with
improvements to the model, the optimization procedures, or the
linguistic representations
\cite{sochergrounded,kalchbrenner2014convolutional}. In addition,
there remain subtle questions about how to fairly assess whether these
models have truly generalized in the way we want them to. There is a
constant tension between giving the models training data that gives
them a chance to learn the target logical functions and revealing the
answer to them in a way that leads to overfitting. The underlying
logical theories provide only limited guidance on this point. Finally,
we have only scratched the surface of the logical complexity of
natural language; in future experiments, we hope to test sentences
with embedded quantifiers, multiple interacting quantifiers, relative
clauses, and other kinds of recursive structure. Nonetheless, the
rapid progress the field has made with these models in recent years
provides ample reason to be optimistic that they can be trained to
meet the challenges of natural language semantics.

% These experiments represent one of the first attempts to reproduce any large fragment of the behavior of a complex logic within a neural network model, and the first attempt that we are aware of to address either the encoding of lexical relations or the learning of recursive operators. This presents considerable challenges in evaluating the particular models that we choose, since we cannot rely on prior results to establish that any particular amount or type of training data is sufficient to teach any model the structure of the logic. The positive results that we have found, however, are extremely promising for the future of learned representation models in the applied modeling of meaning. We have seen that recursive neural tensor networks are able to encode lexical relations accurately and encode recursive operators. We have also seen that both RNNs and RNTNs are able to handle the meanings of quantifiers in an inference setting in at least some cases. 

% There is ample room to build on these results. In the interest of fully mirroring the capacity of existing natural logics in learned models, it would be valuable to extend these experiments to cover other ways in which meanings are encoded in natural language, including challenges such as reasoning over sentences with transitive verbs or relative clauses. In addition, it would be highly informative to compare these results on standard recursive neural networks with other proposed learned models for sentence meaning, such as dependency tree RNNs \cite{sochergrounded}, Belief Propagation RNNs (TODO: cite), or convolutional RNNs \cite{kalchbrenner2014convolutional}.


% TODO: One para of closing discussion.
% - Results strongly suggest that RNTNs can encode the basics of this logic. First such result.
% -- Decay over size in recursion results not ideal, but this kind of behavior may not be problematic since there is a practical bound on the length of natural language sentences.
% - Future work: 
% -- Harder problems
% --- Sentences with more types of structure: Transitive verbs, relative clauses, etc.
% -- More models
% --- BP-RNNs, conv-RNNs
